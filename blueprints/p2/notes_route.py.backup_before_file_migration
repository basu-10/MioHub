from flask import Blueprint, render_template, request, redirect, url_for, flash, session, jsonify, send_file, Response
from flask_login import login_required, current_user

import requests
import uuid
from PIL import Image
import os, re, requests, json, zipfile, tempfile, shutil
from sqlalchemy.exc import SQLAlchemyError
from io import BytesIO
from datetime import datetime
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Image as RLImage, Table as RLTable, HRFlowable
from reportlab.lib.enums import TA_LEFT, TA_CENTER
from reportlab.lib import colors
from bs4 import BeautifulSoup
import markdown


from .models import Note, User, Folder, Board
from extensions import db, login_manager
#from utils import build_folder_breadcrumb, now
from .utils import get_existing_image_by_hash, get_image_hash, allowed_file, convert_to_webp, collect_images_from_content, copy_images_to_user
from utilities_main import  *
from values_main import  *
from . import notes_bp



## ---------------------------------------------------------------------------------------------------
# noteleeper related
# product p2

# view option in note menu # deprecate for raw text with unique link
@notes_bp.route('/note/<int:note_id>')
@login_required
def view_note(note_id):
    return render_template('p2/view_note.html', note="", md_content="")



@notes_bp.route('/delete_note/<int:note_id>', methods=['POST'])
@login_required
def delete_note(note_id):
    note = Note.query.filter_by(id=note_id, user_id=current_user.id).first()
    if note:
        size_to_subtract = calculate_content_size(note.content)
        user_id = current_user.id
        db.session.delete(note)
        db.session.commit()
        # After deleting a note, sync the session asset marks to remove any filenames
        # no longer referenced across any notes or boards for this user.
        try:
            marked = session.get('assets_marked_used', []) or []
            if marked:
                used_filenames = set()
                # NOTE: Do not re-import Note/Board here - use the top-of-file imports to avoid
                # UnboundLocalError (importing in a function makes the name local for that function).
                for n in Note.query.filter_by(user_id=current_user.id).all():
                    if n.content:
                        collect_images_from_content(n.content, used_filenames)
                for b in Board.query.filter_by(user_id=current_user.id).all():
                    if b.content:
                        collect_images_from_content(b.content, used_filenames)
                    if getattr(b, 'description', None):
                        collect_images_from_content(b.description or '', used_filenames)
                session['assets_marked_used'] = [m for m in marked if m in used_filenames]
                session.modified = True
        except Exception:
            pass
        update_user_data_size(current_user, -size_to_subtract)
        
        # Clean up orphaned images
        from .utils import cleanup_orphaned_images_for_user
        try:
            deleted_count, freed_bytes = cleanup_orphaned_images_for_user(user_id)
            if deleted_count > 0:
                print(f"[DELETE NOTE] Cleaned up {deleted_count} orphaned images, freed {freed_bytes} bytes")
        except Exception as e:
            print(f"[DELETE NOTE] Image cleanup failed: {e}")
        
        flash("Note deleted successfully.")
    else:
        flash("Note not found or unauthorized.")
    target_folder_id = session.get('current_folder_id')
    print(f"[DELETE NOTE] Target folder id: {target_folder_id}")
    return redirect(url_for("folders.view_folder", folder_id=target_folder_id))


@notes_bp.route('/new_note', methods=['GET', 'POST'])
@login_required
def new_note():
    current_folder_id = session.get('current_folder_id')

    if not current_folder_id:
        current_folder = Folder.query.filter_by(user_id=current_user.id, parent_id=None).first()
        current_folder_id = current_folder.id

    if request.method == 'POST':
        # Accept missing form keys gracefully
        title = (request.form.get('title') or '').strip()
        description = request.form.get('description', '')
        content = request.form.get('content', '')

        # Process images in content
        content = extract_and_save_images(content, current_user.id)

        # If no title provided, generate a default title
        if not title:
            title = "Default Title " + now
            flash('Title is required! Saved with the title: ' + title)

        # Create the note regardless of whether the title is present or not
        content_size = calculate_content_size(content)
        if not check_guest_limit(current_user, content_size):
            return redirect(url_for('folders.view_folder', folder_id=current_folder_id))

        note = Note(folder_id=current_folder_id, title=title, content=content, user_id=current_user.id)
        # Attach description if valid JSON
        if description:
            try:
                import json as _json
                parsed = _json.loads(description)
                if isinstance(parsed, (dict, list)):
                    note.description = description
            except Exception:
                print(f"DEBUG: new_note - invalid description JSON when creating default note; ignoring")

        db.session.add(note)
        db.session.commit()
        # After saving, sync session asset marks so we don't keep filenames marked as used when
        # they're no longer referenced in any saved Note/Board. This prevents assets from being
        # incorrectly shown as "in use" due to stale session state.
        try:
            marked = session.get('assets_marked_used', []) or []
            if marked:
                # compute actual used filenames across this user's notes and boards
                used_filenames = set()
                # NOTE: Do not re-import Note/Board here - use the top-of-file imports to avoid
                # UnboundLocalError (importing in a function makes the name local for that function).
                for n in Note.query.filter_by(user_id=current_user.id).all():
                    if n.content:
                        collect_images_from_content(n.content, used_filenames)
                for b in Board.query.filter_by(user_id=current_user.id).all():
                    if b.content:
                        collect_images_from_content(b.content, used_filenames)
                    if getattr(b, 'description', None):
                        collect_images_from_content(b.description or '', used_filenames)
                # filter marked
                session['assets_marked_used'] = [m for m in marked if m in used_filenames]
                session.modified = True
        except Exception:
            # Don't block the save process on session cleanup failures
            pass
        update_user_data_size(current_user, content_size)
        flash('Note created successfully!')
        return redirect(url_for('notes.edit_note', note_id=note.id))

    elif request.method == 'GET':
        folder = Folder.query.get(current_folder_id)
        breadcrumb = build_folder_breadcrumb(folder) if folder else []
        return render_template('p2/file_edit_proprietary_note.html', folder_breadcrumb=breadcrumb)

@notes_bp.route('/edit_note/<int:note_id>', methods=['GET', 'POST'])
@login_required
def edit_note(note_id):
    note = Note.query.get_or_404(note_id)
    if note.user_id != current_user.id:
        flash("Access denied.")
        return redirect(url_for('dashboard'))

    if request.method == 'POST':
        title = request.form['title']
        description = request.form.get('description', '')
        content = request.form['content']

        if not title:
            flash('Title is required!')
            return redirect(url_for('notes.edit_note', note_id=note_id))

        # Process images in content
        content = extract_and_save_images(content, current_user.id)

        # Debug: Validate description JSON (if present)
        try:
            if description:
                import json as _json
                _json.loads(description)
                print(f"DEBUG: Edit note {note_id} - description is valid JSON (len={len(description)})")
        except Exception as e:
            preview = (description or '')[:200]
            print(f"DEBUG: Edit note {note_id} - description is NOT valid JSON (preview={preview!r})")

        old_size = calculate_content_size(note.content)
        new_size = calculate_content_size(content)
        delta = new_size - old_size
        if not check_guest_limit(current_user, delta):
            return redirect(url_for('folders.view_folder', folder_id=note.folder_id))
        note.title = title
        # Only accept description if it's valid JSON (dict or list) or empty string -> clear
        if description == '':
            note.description = ''
        else:
            try:
                import json as _json
                parsed = _json.loads(description)
                if isinstance(parsed, (dict, list)):
                    note.description = description
                else:
                    print(f"DEBUG: edit_note - description for note {note_id} not dict/list; ignoring update")
            except Exception:
                print(f"DEBUG: edit_note - invalid JSON description received for note {note_id}; ignoring update")
        note.content = content
        note.last_modified = datetime.utcnow()
        db.session.commit()
        
        # Add notification for successful save
        from blueprints.p2.utils import add_notification
        size_str = f"{new_size / 1024:.1f} KB" if new_size < 1024 * 1024 else f"{new_size / (1024 * 1024):.1f} MB"
        notification_msg = f"Saved note: {note.title} ({size_str})"
        add_notification(current_user.id, notification_msg, 'save')
        
        # After saving, sync session asset marks so we don't keep filenames marked as used when
        # they're no longer referenced in any saved Note/Board. See similar logic in new_note.
        try:
            marked = session.get('assets_marked_used', []) or []
            if marked:
                used_filenames = set()
                # NOTE: Do not re-import Note/Board here - use the top-of-file imports to avoid
                # UnboundLocalError (importing in a function makes the name local for that function).
                for n in Note.query.filter_by(user_id=current_user.id).all():
                    if n.content:
                        collect_images_from_content(n.content, used_filenames)
                for b in Board.query.filter_by(user_id=current_user.id).all():
                    if b.content:
                        collect_images_from_content(b.content, used_filenames)
                    if getattr(b, 'description', None):
                        collect_images_from_content(b.description or '', used_filenames)
                session['assets_marked_used'] = [m for m in marked if m in used_filenames]
                session.modified = True
        except Exception:
            pass
        update_user_data_size(current_user, delta)
        flash('Note updated successfully!')
        return redirect(url_for('notes.edit_note', note_id=note.id))

    breadcrumb = build_folder_breadcrumb(note.folder) if note.folder else []
    return render_template('p2/file_edit_proprietary_note.html', note=note, folder_breadcrumb=breadcrumb)

def extract_and_save_images(content, user_id):
    """
    Extract external images from HTML content and convert to WebP with deduplication, replace with file paths
    """
    

    # Pattern to match external image URLs (http/https)
    external_pattern = r'<img[^>]*src="(https?://[^"]+)"[^>]*>'

    def replace_external_image(match):
        full_match = match.group(0)
        image_url = match.group(1)

        try:
            # Download the image
            response = requests.get(image_url, timeout=10, stream=True)
            response.raise_for_status()

            # Check file size
            content_length = response.headers.get('content-length')
            if content_length and int(content_length) > MAX_IMAGE_SIZE:
                return full_match  # Keep original if too large

            # Read image data
            image_data = response.content
            if len(image_data) > MAX_IMAGE_SIZE:
                return full_match  # Keep original if too large

            # Save temporary file to calculate hash
            temp_original = f"temp_original_{uuid.uuid4().hex}"
            temp_original_path = os.path.join(UPLOAD_FOLDER, temp_original)

            with open(temp_original_path, 'wb') as f:
                f.write(image_data)

            # Calculate hash
            image_hash = get_image_hash(temp_original_path)

            # Check if this image already exists for this user
            existing_url = get_existing_image_by_hash(user_id, image_hash)
            if existing_url:
                # Clean up temp file and use existing image
                os.remove(temp_original_path)
                print(f"DEBUG: Using existing external image for hash {image_hash}: {existing_url}")
                return re.sub(r'src="[^"]*"', f'src="{existing_url}"', full_match)

            # Generate hash-based filename
            filename = f"{user_id}_{image_hash}.webp"
            final_filepath = os.path.join(UPLOAD_FOLDER, filename)

            # Convert to WebP
            convert_to_webp(temp_original_path, final_filepath)

            # Clean up temp file
            os.remove(temp_original_path)

            # Get final file size and update user data size
            if os.path.exists(final_filepath):
                final_file_size = os.path.getsize(final_filepath)

                if not check_guest_limit(current_user, final_file_size):
                    # Remove the file if it would exceed the limit
                    os.remove(final_filepath)
                    return full_match  # Keep original

                update_user_data_size(current_user, final_file_size)

                # Return updated img tag
                relative_path = f"/static/uploads/images/{filename}"
                print(f"DEBUG: Created new external image with hash {image_hash}: {relative_path}")
                return re.sub(r'src="[^"]*"', f'src="{relative_path}"', full_match)

        except Exception as e:
            print(f"Error processing external image {image_url}: {e}")
            return full_match  # Keep original on error

    # Replace all external images
    updated_content = re.sub(external_pattern, replace_external_image, content)

    # Now also handle inline data:image/...;base64,... images and save them to UPLOAD_FOLDER
    from bs4 import BeautifulSoup
    import base64, mimetypes, uuid, shutil
    soup = BeautifulSoup(updated_content, 'html.parser')
    for img in soup.find_all('img'):
        src = img.get('src', '')
        if isinstance(src, str) and src.startswith('data:image/'):
            try:
                header, b64 = src.split(',', 1)
                mime = header.split(';')[0].split(':')[1]
                ext = mimetypes.guess_extension(mime) or '.png'
                tmp = f"tmp_{uuid.uuid4().hex}{ext}"
                tmp_path = os.path.join(UPLOAD_FOLDER, tmp)
                with open(tmp_path, 'wb') as f:
                    f.write(base64.b64decode(b64))
                image_hash = get_image_hash(tmp_path)
                existing_url = get_existing_image_by_hash(user_id, image_hash)
                if existing_url:
                    print(f"DEBUG: extract_and_save_images - inline already exists for user {user_id}: {existing_url}")
                    img['src'] = existing_url
                    try:
                        os.remove(tmp_path)
                    except Exception:
                        pass
                    continue
                dest_filename = f"{user_id}_{image_hash}.webp"
                dest_path = os.path.join(UPLOAD_FOLDER, dest_filename)
                try:
                    converted = convert_to_webp(tmp_path, dest_path)
                    if os.path.exists(converted):
                        img['src'] = f"/static/uploads/images/{os.path.basename(converted)}"
                        print(f"DEBUG: extract_and_save_images - inline converted and saved for user {user_id} -> {converted}")
                        # update user data size
                        try:
                            update_user_data_size(current_user, os.path.getsize(converted))
                        except Exception:
                            pass
                except Exception:
                    try:
                        shutil.copy2(tmp_path, dest_path)
                        if os.path.exists(dest_path):
                            img['src'] = f"/static/uploads/images/{os.path.basename(dest_path)}"
                            try:
                                update_user_data_size(current_user, os.path.getsize(dest_path))
                            except Exception:
                                pass
                    except Exception as e:
                        print(f"Error processing inline data URI: {e}")
                        # keep the original data URI if processing failed
                    continue
                finally:
                    try:
                        if os.path.exists(tmp_path):
                            os.remove(tmp_path)
                    except Exception:
                        pass
            finally:
                pass



    updated_content = str(soup)
    return updated_content





# ========================================================================================
# export import
# core

import os
import io
import zipfile
import json
import re
import base64
from datetime import datetime
from flask import current_app
from bs4 import BeautifulSoup
from werkzeug.utils import secure_filename


COMBINED_BLOCK_TYPES = {"note", "board", "board-iframe"}


def parse_combined_blocks(raw_content):
    if not raw_content:
        return []

    try:
        data = json.loads(raw_content)
    except (json.JSONDecodeError, TypeError):
        return []

    if isinstance(data, list):
        return [block for block in data if isinstance(block, dict)]

    return []


def is_combined_document(raw_content):
    blocks = parse_combined_blocks(raw_content)
    return any(block.get("type") in COMBINED_BLOCK_TYPES for block in blocks)


# util function collect_images_from_content has moved to utils.py. Use imported function.


def folder_to_dict(folder, image_set):
    """
    Convert a folder and all its contents to a dictionary structure
    Recursively includes subfolders
    Collects all image filenames into image_set
    """
    folder_dict = {
        "id": folder.id,
        "name": folder.name,
        "parent_id": folder.parent_id,
        "created_at": folder.created_at.isoformat() if hasattr(folder, 'created_at') and folder.created_at else None,
        "notes": [],
        "boards": [],
        "children": []
    }
    
    # Export notes with all fields
    for note in folder.notes:
        note_dict = {
            "id": note.id,
            "title": note.title,
            "content": note.content,
            "created_at": note.created_at.isoformat() if hasattr(note, 'created_at') and note.created_at else None,
            "is_public": note.is_public if hasattr(note, 'is_public') else False,
            "is_pinned": note.is_pinned if hasattr(note, 'is_pinned') else False
        }
        
        # Collect images from note content
        if note.content:
            collect_images_from_content(note.content, image_set)
        
        folder_dict["notes"].append(note_dict)
    
    # Export boards with all fields
    for board in folder.boards:
        board_dict = {
            "id": board.id,
            "title": board.title,
            "content": board.content,
            "created_at": board.created_at.isoformat() if hasattr(board, 'created_at') and board.created_at else None
        }
        folder_dict["boards"].append(board_dict)
    
    # Recursively export subfolders
    for subfolder in folder.children:
        folder_dict["children"].append(folder_to_dict(subfolder, image_set))
    
    return folder_dict



@notes_bp.route('/export_notes', methods=['GET'])
@login_required
def export_notes():
    """
    Export folder hierarchy with notes, boards, and images in JSON format.
    Images are copied as-is (no re-compression) to preserve original WebP quality.
    """
    current_folder_id = session.get("current_folder_id")
    user_id = current_user.id
    username = current_user.username

    print("[EXPORT] current_folder_id: ", current_folder_id)
    print("[EXPORT] current_user_id: ", user_id)
    print("[EXPORT] username: ", username)

    if current_folder_id:
        start_folder = Folder.query.filter_by(
            id=current_folder_id,
            user_id=user_id
        ).first()
    else:
        # fallback to root if nothing stored
        start_folder = Folder.query.filter_by(user_id=user_id, parent_id=None).first()

    if not start_folder:
        print("[EXPORT] Folder not found")
        flash("Folder not found.", "danger")
        return redirect(url_for("folders.view_folder",
                                folder_id=session.get("current_folder_id", 0)))

    # Collect all images referenced in content
    image_set = set()
    
    # Convert folder hierarchy to dict and collect images
    folder_data = folder_to_dict(start_folder, image_set)
    
    # Create export package
    export_data = {
        "export_version": "3.0",
        "export_date": datetime.now().isoformat(),
        "user": username,
        "start_folder_name": start_folder.name,
        "start_folder_id": start_folder.id,
        "folder": folder_data,
        "image_count": len(image_set)
    }

    # Create ZIP file
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
        # Write main data JSON
        zipf.writestr("export_data.json", json.dumps(export_data, indent=2))
        
        # Copy images to ZIP without re-compression
        images_added = 0
        for image_filename in image_set:
            # Try to find the image file
            possible_paths = [
                os.path.normpath(os.path.join('static', 'uploads', 'images', image_filename)),
                os.path.normpath(os.path.join(UPLOAD_FOLDER, image_filename))
            ]
            
            for image_path in possible_paths:
                if os.path.exists(image_path) and os.path.isfile(image_path):
                    # Add image to ZIP with path "images/filename"
                    zip_image_path = f"images/{image_filename}"
                    zipf.write(image_path, zip_image_path)
                    images_added += 1
                    print(f"[EXPORT] Added image: {image_filename}")
                    break
            else:
                print(f"[EXPORT] Warning: Image not found: {image_filename}")
        
        print(f"[EXPORT] Added {images_added} images to ZIP")

    zip_buffer.seek(0)
    zip_filename = f"{username}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
    
    flash(f"Exported folder with {len(image_set)} images.", "success")
    return send_file(zip_buffer, mimetype="application/zip", as_attachment=True, download_name=zip_filename)








def sanitize_filename(filename):
    """
    Clean filename for safe file system usage
    """
    if not filename:
        return "Untitled"

    # Replace problematic characters
    sanitized = re.sub(r'[<>:"/\\|?*]', '_', filename)
    # Remove leading/trailing dots and spaces
    sanitized = sanitized.strip('. ')
    # Limit length
    if len(sanitized) > 100:
        sanitized = sanitized[:100]

    return sanitized or "Untitled"





from docx.text.run import Run as _DocxRun

def _get_paragraph_indent_px(para, p_elem=None, ns=None):
    """
    Return left-indent in pixels for a paragraph.
    Prefer python-docx Paragraph.paragraph_format.left_indent when available.
    If missing, read the raw w:ind/@w:left (twips) from the XML element (if provided).
    Conversion: twips -> points (twips/20) -> px (~1.33 * points).
    """
    try:
        left = para.paragraph_format.left_indent
        if left:
            return int(left.pt * 1.33)
    except Exception:
        pass

    # Fallback: read w:ind/@w:left from paragraph XML (twips)
    if p_elem is not None and ns is not None:
        try:
            vals = p_elem.xpath('.//w:ind/@w:left', namespaces=ns)
            if vals:
                twips = int(vals[0])
                points = twips / 20.0
                return int(points * 1.33)
        except Exception:
            pass

    return 0



def _extract_textbox_with_newlines(txbx_element, ns, doc):
    """
    Given an XML element that represents a textbox container (txbxContent or sdt),
    return HTML with paragraphs preserved. Uses python-docx Paragraph wrapper
    for accurate text extraction.
    """
    parts = []
    # find all w:p descendants (paragraphs) inside the textbox element
    for p_elem in txbx_element.xpath('.//w:p', namespaces=ns):
        p = _DocxParagraph(p_elem, doc)
        html_text = _runs_to_html(p).strip()
        if html_text:
            px = _get_paragraph_indent_px(p, p_elem, ns)
            indent_attr = f" style='margin-left:{px}px;'" if px else ""
            parts.append(f"<p{indent_attr}>{html_text}</p>")



    return "".join(parts)


def _runs_to_html(paragraph):
    """Convert a python-docx Paragraph into HTML with <b>, <i>, <u> where needed."""
    parts = []
    for run in paragraph.runs:
        text = run.text.replace("<", "&lt;").replace(">", "&gt;")
        if not text:
            continue
        if run.bold:
            text = f"<b>{text}</b>"
        if run.italic:
            text = f"<i>{text}</i>"
        if run.underline:
            text = f"<u>{text}</u>"
        parts.append(text)
    return "".join(parts)



import docx
import openpyxl
from docx.table import Table as _DocxTable
from docx.text.paragraph import Paragraph as _DocxParagraph
from docx.text.run import Run as _DocxRun



# w excel word support
@notes_bp.route('/import_files', methods=['POST'])
@login_required
def import_files():
    target_folder_id = request.form.get("target_folder_id")
    print(f"[IMPORT_FILES] Target folder id: {target_folder_id}")

    uploaded_files = request.files.getlist("import_files")
    if not uploaded_files or uploaded_files == [None]:
        flash("No files provided.", "danger")
        return redirect(url_for("folders.view_folder", folder_id=target_folder_id))

    imported_notes = 0
    target_folder = Folder.query.get(target_folder_id)

    for uploaded_file in uploaded_files:
        filename = secure_filename(uploaded_file.filename)
        ext = os.path.splitext(filename)[1].lower()

        if ext not in (".html", ".txt", ".docx", ".xlsx"):
            flash(f"Skipped {filename}: only .html, .txt, .docx, .xlsx allowed.", "warning")
            continue

        try:
            content = ""
            if ext == ".html":
                raw_data = uploaded_file.read().decode("utf-8", errors="ignore")
                content = extract_and_save_images(raw_data, current_user.id)

            elif ext == ".txt":
                raw_data = uploaded_file.read().decode("utf-8", errors="ignore")
                content = f"<pre>{raw_data}</pre>"

            elif ext == ".docx":
                doc = docx.Document(uploaded_file)
                parts = []
                ns = {"w": "http://schemas.openxmlformats.org/wordprocessingml/2006/main"}

                # iterate children of body to preserve original order (paras, tables, textboxes)
                for element in doc.element.body:
                    tag_local = element.tag.split('}')[-1]

                    if tag_local == 'tbl':
                        # create a Table wrapper from the XML element and render to HTML
                        tbl = _DocxTable(element, doc)
                        rows = []
                        for r in tbl.rows:
                            cells = []
                            for c in r.cells:
                                # join cell paragraphs (preserve runs/styles) with <br/> to preserve line breaks inside a cell
                                para_texts = [_runs_to_html(p).strip() for p in c.paragraphs]
                                cell_text = "<br/>".join(t for t in para_texts if t)
                                cells.append(f"<td>{cell_text}</td>")
                            rows.append(f"<tr>{''.join(cells)}</tr>")
                        parts.append("<table border='1' style='border-collapse:collapse;'>")
                        parts.extend(rows)
                        parts.append("</table>")

                    elif tag_local == 'p':
                        para = _DocxParagraph(element, doc)
                        html_text = _runs_to_html(para).strip()
                        if html_text:
                            px = _get_paragraph_indent_px(para, element, ns)
                            indent_attr = f" style='margin-left:{px}px;'" if px else ""
                            parts.append(f"<p{indent_attr}>{html_text}</p>")



                    elif tag_local in ('sdt', 'txbxContent'):
                        textbox_text = _extract_textbox_with_newlines(element, ns, doc)
                        if textbox_text:
                            parts.append(f"<div class='textbox'>{textbox_text}</div>")

                content = "".join(parts)





            elif ext == ".xlsx":
                wb = openpyxl.load_workbook(uploaded_file, data_only=True)
                sheet_tables = []

                for sheet in wb.worksheets:
                    # Start table
                    html = [f"<h4>{sheet.title}</h4>", "<table border='1' style='border-collapse:collapse;'>"]

                    for row in sheet.iter_rows(values_only=True):
                        html.append("<tr>")
                        for cell in row:
                            val = "" if cell is None else str(cell)
                            html.append(f"<td>{val}</td>")
                        html.append("</tr>")

                    html.append("</table>")
                    sheet_tables.append("".join(html))

                content = "<hr>".join(sheet_tables)


            title = os.path.splitext(filename)[0] or "Untitled"
            note = Note(
                folder_id=target_folder.id,
                user_id=current_user.id,
                title=title,
                content=content
            )
            db.session.add(note)
            imported_notes += 1

        except Exception as e:
            current_app.logger.exception(f"Failed to import {filename}")
            flash(f"Error importing {filename}: {e}", "danger")

    db.session.commit()
    flash(f"Imported {imported_notes} notes.", "success")

    return redirect(url_for("folders.view_folder", folder_id=target_folder_id))







def dict_to_folder(folder_dict, parent_folder, user_id, id_mapping, imported_images):
    """
    Recursively create folder structure from dictionary
    Returns the created folder and updates id_mapping
    """
    # Create folder
    new_folder = Folder(
        name=folder_dict["name"],
        user_id=user_id,
        parent_id=parent_folder.id if parent_folder else None
    )
    db.session.add(new_folder)
    db.session.flush()  # Get the ID
    
    # Map old ID to new ID
    old_id = folder_dict["id"]
    id_mapping[f"folder_{old_id}"] = new_folder.id
    
    # Create notes
    for note_dict in folder_dict.get("notes", []):
        # Content stays as-is, images are already copied to disk
        note = Note(
            title=note_dict["title"],
            content=note_dict["content"],
            folder_id=new_folder.id,
            user_id=user_id
        )
        db.session.add(note)
    
    # Create boards
    for board_dict in folder_dict.get("boards", []):
        board = Board(
            title=board_dict["title"],
            content=board_dict["content"],
            folder_id=new_folder.id,
            user_id=user_id
        )
        db.session.add(board)
    
    # Recursively create children
    for child_dict in folder_dict.get("children", []):
        dict_to_folder(child_dict, new_folder, user_id, id_mapping, imported_images)
    
    return new_folder


@notes_bp.route('/import_notes', methods=['POST'])
@login_required
def import_notes():
    """
    Import ZIP backup with JSON structure and original WebP images.
    Images are copied directly without re-compression.
    """
    target_folder_id = request.form.get("target_folder_id", type=int)
    print(f"[IMPORT] Target folder id: {target_folder_id}")

    uploaded_file = request.files.get("import_zip")
    if uploaded_file is None:
        flash("No file provided.", "danger")
        return redirect(url_for("folders.view_folder", folder_id=target_folder_id))

    filename = uploaded_file.filename or ""
    if not filename.lower().endswith(".zip"):
        flash("Please upload a ZIP file.", "warning")
        return redirect(url_for("folders.view_folder", folder_id=target_folder_id))

    print(f"[IMPORT] Uploaded filename: {filename}")
    
    zip_bytes = uploaded_file.read()
    print(f"[IMPORT] File size: {len(zip_bytes)} bytes")

    imported_notes = 0
    imported_boards = 0
    imported_images = 0
    id_mapping = {}

    try:
        with zipfile.ZipFile(io.BytesIO(zip_bytes)) as zf:
            # Check for export_data.json (new format v3.0)
            if "export_data.json" in zf.namelist():
                print("[IMPORT] Detected new JSON format (v3.0)")
                
                # Read export data
                with zf.open("export_data.json") as f:
                    export_data = json.load(f)
                
                folder_data = export_data.get("folder", {})
                
                # First, extract and copy all images WITHOUT re-compression
                image_files = [n for n in zf.namelist() if n.startswith("images/")]
                print(f"[IMPORT] Found {len(image_files)} images in ZIP")
                
                os.makedirs(UPLOAD_FOLDER, exist_ok=True)
                
                for image_path in image_files:
                    image_filename = os.path.basename(image_path)
                    
                    # Extract image to disk
                    image_data = zf.read(image_path)
                    target_path = os.path.join(UPLOAD_FOLDER, image_filename)
                    
                    # Only copy if it doesn't already exist
                    if not os.path.exists(target_path):
                        with open(target_path, 'wb') as img_file:
                            img_file.write(image_data)
                        
                        # Update user data size
                        file_size = len(image_data)
                        update_user_data_size(current_user, file_size)
                        imported_images += 1
                        print(f"[IMPORT] Copied image: {image_filename} ({file_size} bytes)")
                    else:
                        print(f"[IMPORT] Image already exists: {image_filename}")
                
                # Get target parent folder
                target_folder = None
                if target_folder_id:
                    target_folder = Folder.query.get(target_folder_id)
                
                if not target_folder:
                    target_folder = Folder.query.filter_by(
                        user_id=current_user.id, 
                        parent_id=None
                    ).first()
                
                # Create folder structure recursively
                dict_to_folder(folder_data, target_folder, current_user.id, id_mapping, imported_images)
                
                # Count imported items
                def count_items(folder_dict):
                    notes = len(folder_dict.get("notes", []))
                    boards = len(folder_dict.get("boards", []))
                    for child in folder_dict.get("children", []):
                        child_notes, child_boards = count_items(child)
                        notes += child_notes
                        boards += child_boards
                    return notes, boards
                
                imported_notes, imported_boards = count_items(folder_data)
                
                db.session.commit()
                
                summary_parts = []
                if imported_notes:
                    summary_parts.append(f"{imported_notes} notes")
                if imported_boards:
                    summary_parts.append(f"{imported_boards} boards")
                if imported_images:
                    summary_parts.append(f"{imported_images} images")
                
                if summary_parts:
                    flash(f"Imported {', '.join(summary_parts)}.", "success")
                else:
                    flash("No content imported from archive.", "info")
                
                print(f"[IMPORT] Successfully imported: {imported_notes} notes, {imported_boards} boards, {imported_images} images")
            
            else:
                # Legacy format - show error
                flash("Unsupported backup format. Please export a new backup and try again.", "danger")
                print("[IMPORT] Legacy format detected - not supported in new version")

    except zipfile.BadZipFile:
        flash("Invalid ZIP file.", "danger")
        print("[IMPORT] Invalid ZIP file")
    except Exception as e:
        db.session.rollback()
        current_app.logger.exception("Import failed")
        flash(f"Import error: {str(e)}", "danger")
        print(f"[IMPORT] Error: {e}")

    return redirect(url_for("folders.view_folder", folder_id=target_folder_id))





# Add new route for handling image uploads from Summernote
@notes_bp.route('/upload_image', methods=['POST'])
@login_required
def upload_image():
    """
    Handle direct image uploads from Summernote - convert all to WebP with deduplication
    """
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No file selected'}), 400

    if not allowed_file(file.filename):
        return jsonify({'error': 'Invalid file type'}), 400

    try:
        # Ensure upload directory exists
        os.makedirs(UPLOAD_FOLDER, exist_ok=True)
        
        # Check file size
        file.seek(0, os.SEEK_END)
        file_size = file.tell()
        file.seek(0)

        if file_size > MAX_IMAGE_SIZE:
            return jsonify({'error': 'File too large'}), 400

        # Save temporary file first to calculate hash
        temp_original = f"temp_original_{uuid.uuid4().hex}"
        temp_original_path = os.path.join(UPLOAD_FOLDER, temp_original)
        file.save(temp_original_path)

        # Calculate hash of original file
        image_hash = get_image_hash(temp_original_path)

        # Check if this image already exists for this user
        existing_url = get_existing_image_by_hash(current_user.id, image_hash)
        if existing_url:
            # Clean up temp file and return existing image URL
            os.remove(temp_original_path)
            print(f"DEBUG: Using existing image for hash {image_hash}: {existing_url}")
            return jsonify({'url': existing_url})

        # Generate hash-based filename - always WebP
        filename = f"{current_user.id}_{image_hash}.webp"
        final_filepath = os.path.join(UPLOAD_FOLDER, filename)

        # Convert to WebP
        actual_filepath = convert_to_webp(temp_original_path, final_filepath)

        # Clean up temp file
        os.remove(temp_original_path)

        # Get final file size and update user data size
        if os.path.exists(actual_filepath):
            final_file_size = os.path.getsize(actual_filepath)

            if not check_guest_limit(current_user, final_file_size):
                # Remove the file if it would exceed the limit
                os.remove(actual_filepath)
                return jsonify({'error': 'Storage limit exceeded'}), 400

            update_user_data_size(current_user, final_file_size)

        # Return URL for Summernote
        filename = os.path.basename(actual_filepath)
        url = f"/static/uploads/images/{filename}"
        print(f"DEBUG: Created new image with hash {image_hash}: {url}")
        return jsonify({'url': url})

    except Exception as e:
        print(f"Error uploading image: {e}")
        return jsonify({'error': 'Upload failed'}), 500




# Update autosave functions
@notes_bp.post("/autosave")
@login_required
def autosave():
    note_id = request.form.get("note_id", type=int)
    title = (request.form.get("title") or "").strip()
    content = request.form.get("content") or ""
    description = request.form.get("description") or ''

    if not (note_id or content or title):
        return Response(status=204)

    try:
        if note_id:
            note = Note.query.get_or_404(note_id)
            if note.user_id != current_user.id:
                return Response("Forbidden", status=403)

            # Process images in content
            content = extract_and_save_images(content, current_user.id)

            # Update title if provided
            if title:
                note.title = title

            # Compute size delta for content and update
            old_size = calculate_content_size(note.content)
            new_size = calculate_content_size(content)
            delta = new_size - old_size
            if not check_guest_limit(current_user, delta):
                return Response("Data limit exceeded", status=400)
            note.content = content
            note.last_modified = datetime.utcnow()

            # Update description if present and valid JSON
            if description is not None and description != '':
                try:
                    import json as _json
                    parsed = _json.loads(description)
                    if isinstance(parsed, (dict, list)):
                        note.description = description
                    else:
                        print(f"DEBUG: autosave - description for note {note_id} not dict/list; ignoring")
                except Exception:
                    print(f"DEBUG: autosave - failed to parse description JSON for note {note_id}; ignoring")

            db.session.commit()
            update_user_data_size(current_user, delta)
            # Update description if present and valid JSON
            if description:
                try:
                    import json as _json
                    parsed = _json.loads(description)
                    if isinstance(parsed, (dict, list)):
                        note.description = description
                        db.session.commit()
                    else:
                        print(f"DEBUG: autosave - description for note {note_id} not dict/list; ignoring")
                except Exception:
                    print(f"DEBUG: autosave - failed to parse description JSON for note {note_id}; ignoring")
    except SQLAlchemyError:
        db.session.rollback()
        return Response(status=204)

    return Response(status=204)

@notes_bp.post("/autosave_draft")
@login_required
def autosave_draft():
    title = (request.form.get("title") or "").strip()
    content = request.form.get("content") or ""
    description = request.form.get("description") or ''

    current_folder_id = session.get('current_folder_id')
    if not current_folder_id:
        root_folder = Folder.query.filter_by(user_id=current_user.id, parent_id=None).first()
        if root_folder:
            current_folder_id = root_folder.id
        else:
            # Create root folder if it doesn't exist
            root_folder = Folder(name="Root", user_id=current_user.id)
            db.session.add(root_folder)
            db.session.commit()
            current_folder_id = root_folder.id

    try:
        # Process images in content
        content = extract_and_save_images(content, current_user.id)

        # If there's any meaningful data (title or content), create a draft note
        if title or content or description:
            # If title empty, generate a default title
            if not title:
                title = f"Untitled on {now}"
            content_size = calculate_content_size(content)
            if not check_guest_limit(current_user, content_size):
                return jsonify({"ok": False, "error": "Data limit exceeded"}), 400
            note = Note(folder_id=current_folder_id, title=title, content=content, user_id=current_user.id)
            # Try to set description only if valid JSON (dict or list)
            if description:
                try:
                    import json as _json
                    parsed = _json.loads(description)
                    if isinstance(parsed, (dict, list)):
                        note.description = description
                    else:
                        print(f"DEBUG: autosave_draft - description is not dict/list; ignoring for new note")
                except Exception:
                    print(f"DEBUG: autosave_draft - invalid JSON description; ignoring for new note")
            db.session.add(note)
            db.session.commit()
            update_user_data_size(current_user, content_size)
            return jsonify({"ok": True, "note_id": note.id, "edit_url": url_for('notes.edit_note', note_id=note.id)}), 200
    except SQLAlchemyError as e:
        db.session.rollback()
        return jsonify({"ok": False, "error": "autosave_draft_failed"}), 500


@notes_bp.route('/export_folder_as_pdf')
@login_required
def export_folder_as_pdf():
    """
    Export all MioNotes, MioDraws, and MioBooks from the current folder as individual PDFs in a ZIP file.
    Maintains folder structure and converts each item to a separate PDF.
    """
    current_folder_id = session.get("current_folder_id")
    user_id = current_user.id
    username = current_user.username

    if current_folder_id:
        start_folder = Folder.query.filter_by(
            id=current_folder_id,
            user_id=user_id
        ).first()
    else:
        start_folder = Folder.query.filter_by(user_id=user_id, parent_id=None).first()

    if not start_folder:
        flash("Folder not found.", "danger")
        return redirect(url_for("folders.view_folder",
                                folder_id=session.get("current_folder_id", 0)))

    # Create a temporary directory to hold the PDF files
    temp_dir = tempfile.mkdtemp()
    
    try:
        # Define PDF styles once (reused for all PDFs)
        styles = getSampleStyleSheet()
        
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=20,
            textColor=colors.HexColor('#1a365d'),
            spaceAfter=20,
            alignment=TA_LEFT,
            fontName='Helvetica-Bold'
        )
        
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontSize=14,
            textColor=colors.HexColor('#2c5282'),
            spaceAfter=10,
            spaceBefore=10,
            fontName='Helvetica-Bold'
        )
        
        normal_style = ParagraphStyle(
            'CustomNormal',
            parent=styles['Normal'],
            fontSize=11,
            leading=14,
            spaceAfter=6
        )
        
        code_style = ParagraphStyle(
            'CodeStyle',
            parent=styles['Normal'],
            fontName='Courier',
            fontSize=9,
            leading=11,
            leftIndent=20,
            backgroundColor=colors.HexColor('#f5f5f5'),
            spaceAfter=6
        )
        
        # Helper function to sanitize filename
        def sanitize_filename(filename):
            """Remove or replace invalid filename characters"""
            # Replace invalid characters with underscore
            invalid_chars = '<>:"/\\|?*'
            for char in invalid_chars:
                filename = filename.replace(char, '_')
            # Limit length
            return filename[:200]
        
        # Helper function to create a PDF for a single note
        def create_note_pdf(note, folder_path):
            """Create a PDF for a single MioNote note"""
            try:
                pdf_filename = sanitize_filename(f"{note.title}.pdf")
                pdf_path = os.path.join(folder_path, pdf_filename)
                
                # Create PDF
                buffer = BytesIO()
                doc = SimpleDocTemplate(buffer, pagesize=letter,
                                       rightMargin=72, leftMargin=72,
                                       topMargin=72, bottomMargin=72)
                
                elements = []
                
                # Add title
                elements.append(Paragraph(note.title, title_style))
                elements.append(Spacer(1, 0.2*inch))
                
                # Add metadata
                meta_text = f"Type: MioNote | Created: {note.created_at.strftime('%Y-%m-%d %H:%M')}"
                elements.append(Paragraph(meta_text, ParagraphStyle('Meta', parent=styles['Normal'], fontSize=9, textColor=colors.grey)))
                elements.append(Spacer(1, 0.3*inch))
                
                # Convert HTML content to formatted PDF content
                if note.content:
                    soup = BeautifulSoup(note.content, 'html.parser')
                    
                    # Remove script and style elements
                    for script in soup(["script", "style"]):
                        script.decompose()
                    
                    # Process top-level elements only (not descendants) to avoid duplication
                    def process_element(elem, level=0):
                        """Recursively process elements and convert to PDF content"""
                        if not hasattr(elem, 'name') or elem.name is None:
                            # This is a text node
                            return
                        
                        tag = elem.name.lower()
                        
                        # Headings
                        if tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                            text = elem.get_text().strip()
                            if text:
                                # Escape special characters
                                text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                                try:
                                    elements.append(Paragraph(text, heading_style))
                                    elements.append(Spacer(1, 0.1*inch))
                                except Exception as e:
                                    print(f"[PDF] Error with heading: {e}")
                        
                        # Paragraphs
                        elif tag == 'p':
                            # Check if paragraph contains images
                            imgs = elem.find_all('img', recursive=False)
                            if imgs:
                                # Process images in paragraph
                                for img in imgs:
                                    process_element(img, level)
                            
                            # Process text content
                            text = elem.get_text().strip()
                            if text:
                                # Escape special characters
                                text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                                try:
                                    elements.append(Paragraph(text, normal_style))
                                    elements.append(Spacer(1, 0.08*inch))
                                except Exception as e:
                                    print(f"[PDF] Error with paragraph: {e}")
                        
                        # Preformatted text / code blocks
                        elif tag in ['pre', 'code']:
                            text = elem.get_text().strip()
                            if text:
                                # Escape special characters
                                text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                                try:
                                    elements.append(Paragraph(text, code_style))
                                    elements.append(Spacer(1, 0.08*inch))
                                except Exception as e:
                                    print(f"[PDF] Error with code: {e}")
                        
                        # Lists
                        elif tag in ['ul', 'ol']:
                            for li in elem.find_all('li', recursive=False):
                                text = li.get_text().strip()
                                if text:
                                    # Escape special characters
                                    text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                                    bullet = '' if tag == 'ul' else f"{elem.find_all('li', recursive=False).index(li) + 1}."
                                    try:
                                        elements.append(Paragraph(f"{bullet} {text}", normal_style))
                                        elements.append(Spacer(1, 0.05*inch))
                                    except Exception as e:
                                        print(f"[PDF] Error with list item: {e}")
                        
                        # Tables
                        elif tag == 'table':
                            try:
                                table_data = []
                                for row in elem.find_all('tr'):
                                    row_data = []
                                    for cell in row.find_all(['td', 'th']):
                                        cell_text = cell.get_text().strip().replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                                        row_data.append(cell_text)
                                    if row_data:
                                        table_data.append(row_data)
                                
                                if table_data:
                                    t = RLTable(table_data)
                                    t.setStyle([
                                        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
                                        ('BACKGROUND', (0, 0), (-1, 0), colors.lightgrey),
                                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                                        ('FONTSIZE', (0, 0), (-1, -1), 9),
                                        ('PADDING', (0, 0), (-1, -1), 6),
                                    ])
                                    elements.append(t)
                                    elements.append(Spacer(1, 0.1*inch))
                            except Exception as e:
                                print(f"[PDF] Error with table: {e}")
                        
                        # Images
                        elif tag == 'img':
                            try:
                                img_src = elem.get('src', '')
                                if img_src:
                                    img_path = None
                                    
                                    # Handle various local image path formats
                                    if any(prefix in img_src for prefix in ['/static/uploads/images/', 'static/uploads/images/', '/uploads/images/', 'uploads/images/']):
                                        # Extract filename
                                        filename = img_src.split('/')[-1]
                                        
                                        # Try multiple possible paths
                                        possible_paths = [
                                            os.path.join(UPLOAD_FOLDER, filename),
                                            os.path.normpath(os.path.join('static', 'uploads', 'images', filename)),
                                            os.path.normpath(os.path.join(os.getcwd(), 'static', 'uploads', 'images', filename))
                                        ]
                                        
                                        for path in possible_paths:
                                            if os.path.exists(path) and os.path.isfile(path):
                                                img_path = path
                                                break
                                        
                                        if img_path:
                                            try:
                                                # Get image dimensions to calculate proper size
                                                from PIL import Image as PILImage
                                                with PILImage.open(img_path) as pil_img:
                                                    img_width, img_height = pil_img.size
                                                    aspect_ratio = img_height / img_width
                                                    
                                                    # Set max width to 5 inches
                                                    max_width = 5 * inch
                                                    pdf_width = min(max_width, img_width)
                                                    pdf_height = pdf_width * aspect_ratio
                                                    
                                                    # Add image to PDF
                                                    img = RLImage(img_path, width=pdf_width, height=pdf_height)
                                                    elements.append(img)
                                                    elements.append(Spacer(1, 0.15*inch))
                                                    print(f"[PDF] Added image: {filename} ({img_width}x{img_height})")
                                            except Exception as img_error:
                                                print(f"[PDF] Error processing image {filename}: {img_error}")
                                                # Add placeholder text
                                                elements.append(Paragraph(f"[Image: {filename}]", normal_style))
                                                elements.append(Spacer(1, 0.05*inch))
                                        else:
                                            print(f"[PDF] Image not found: {filename}")
                                            elements.append(Paragraph(f"[Image not found: {filename}]", normal_style))
                                            elements.append(Spacer(1, 0.05*inch))
                                    
                                    # Handle external images (note them)
                                    elif img_src.startswith('http'):
                                        elements.append(Paragraph(f"[External image: {img_src[:60]}...]", normal_style))
                                        elements.append(Spacer(1, 0.05*inch))
                                    
                                    # Handle base64 images
                                    elif img_src.startswith('data:image'):
                                        elements.append(Paragraph("[Embedded base64 image]", normal_style))
                                        elements.append(Spacer(1, 0.05*inch))
                                        
                            except Exception as e:
                                print(f"[PDF] Error with image element: {e}")
                                import traceback
                                traceback.print_exc()
                        
                        # Dividers
                        elif tag == 'hr':
                            elements.append(HRFlowable(width="100%", thickness=1, color=colors.grey))
                            elements.append(Spacer(1, 0.1*inch))
                        
                        # Block quotes
                        elif tag == 'blockquote':
                            text = elem.get_text().strip()
                            if text:
                                text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                                quote_style = ParagraphStyle(
                                    'Quote',
                                    parent=normal_style,
                                    leftIndent=30,
                                    rightIndent=30,
                                    textColor=colors.HexColor('#555555'),
                                    fontName='Helvetica-Oblique'
                                )
                                try:
                                    elements.append(Paragraph(f'"{text}"', quote_style))
                                    elements.append(Spacer(1, 0.1*inch))
                                except Exception as e:
                                    print(f"[PDF] Error with blockquote: {e}")
                        
                        # Divs - process children (including images)
                        elif tag in ['div', 'section', 'article', 'main', 'body']:
                            for child in elem.children:
                                process_element(child, level + 1)
                        
                        # Spans and other inline elements - check for images
                        elif tag in ['span', 'a', 'strong', 'em', 'b', 'i', 'u']:
                            # Check for nested images
                            imgs = elem.find_all('img')
                            if imgs:
                                for img in imgs:
                                    process_element(img, level)
                            # Process text if no images
                            elif elem.get_text().strip():
                                text = elem.get_text().strip()
                                text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                                try:
                                    elements.append(Paragraph(text, normal_style))
                                    elements.append(Spacer(1, 0.05*inch))
                                except Exception as e:
                                    print(f"[PDF] Error with inline element: {e}")
                        
                        # Line breaks
                        elif tag == 'br':
                            elements.append(Spacer(1, 0.05*inch))
                    
                    # First, handle any standalone images in the content
                    all_images = soup.find_all('img')
                    processed_images = set()
                    
                    # Process body content
                    body = soup.find('body')
                    if body:
                        for child in body.children:
                            process_element(child)
                    else:
                        # No body tag, process all top-level elements
                        for child in soup.children:
                            process_element(child)
                    
                    # Fallback: if no structured content was found, get all text
                    if len(elements) <= 3:  # Only title and metadata
                        text = soup.get_text()
                        if text.strip():
                            # Escape special characters
                            text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                            paragraphs = text.split('\n')
                            for para in paragraphs:
                                para = para.strip()
                                if para:
                                    try:
                                        elements.append(Paragraph(para, normal_style))
                                        elements.append(Spacer(1, 0.05*inch))
                                    except Exception as e:
                                        print(f"[PDF] Error with fallback paragraph: {e}")
                else:
                    elements.append(Paragraph("(Empty note)", normal_style))
                
                # Build PDF
                doc.build(elements)
                buffer.seek(0)
                
                # Write to file
                with open(pdf_path, 'wb') as f:
                    f.write(buffer.read())
                
                return True
                
            except Exception as e:
                print(f"[PDF EXPORT] Error creating PDF for note {note.id}: {e}")
                return False
        
        # Helper function to create a PDF for a board
        def create_board_pdf(board, folder_path):
            """Create a PDF for a MioDraw (whiteboard)"""
            try:
                pdf_filename = sanitize_filename(f"{board.title}_MioDraw.pdf")
                pdf_path = os.path.join(folder_path, pdf_filename)
                
                buffer = BytesIO()
                doc = SimpleDocTemplate(buffer, pagesize=letter,
                                       rightMargin=72, leftMargin=72,
                                       topMargin=72, bottomMargin=72)
                
                elements = []
                
                # Add title
                elements.append(Paragraph(board.title, title_style))
                elements.append(Spacer(1, 0.2*inch))
                
                # Add metadata
                meta_text = f"Type: MioDraw (Whiteboard) | Created: {board.created_at.strftime('%Y-%m-%d %H:%M')}"
                elements.append(Paragraph(meta_text, ParagraphStyle('Meta', parent=styles['Normal'], fontSize=9, textColor=colors.grey)))
                elements.append(Spacer(1, 0.3*inch))
                
                # Try to extract information from board content (JSON)
                if board.content:
                    try:
                        board_data = json.loads(board.content)
                        
                        # Display board info
                        elements.append(Paragraph("MioDraw Content Summary:", heading_style))
                        elements.append(Spacer(1, 0.1*inch))
                        
                        # Extract text elements if available
                        if isinstance(board_data, dict):
                            # Check for common whiteboard data structures
                            if 'objects' in board_data:
                                objects = board_data['objects']
                                elements.append(Paragraph(f"Total elements: {len(objects)}", normal_style))
                                
                                # Extract text from objects
                                text_items = []
                                for obj in objects:
                                    if isinstance(obj, dict):
                                        if obj.get('type') == 'text' or 'text' in obj:
                                            text_content = obj.get('text', obj.get('content', ''))
                                            if text_content:
                                                text_items.append(text_content)
                                
                                if text_items:
                                    elements.append(Spacer(1, 0.2*inch))
                                    elements.append(Paragraph("Text Content:", heading_style))
                                    for text in text_items:
                                        elements.append(Paragraph(f" {text}", normal_style))
                                        elements.append(Spacer(1, 0.05*inch))
                                else:
                                    elements.append(Paragraph("This MioDraw contains visual elements (shapes, drawings, etc.) that cannot be fully represented in PDF format.", normal_style))
                            else:
                                elements.append(Paragraph("This MioDraw contains visual whiteboard content that cannot be fully represented in PDF format.", normal_style))
                        else:
                            elements.append(Paragraph("This MioDraw contains visual whiteboard content.", normal_style))
                        
                    except json.JSONDecodeError:
                        elements.append(Paragraph("This MioDraw contains visual whiteboard content.", normal_style))
                else:
                    elements.append(Paragraph("(Empty MioDraw)", normal_style))
                
                # Build PDF
                doc.build(elements)
                buffer.seek(0)
                
                # Write to file
                with open(pdf_path, 'wb') as f:
                    f.write(buffer.read())
                
                return True
                
            except Exception as e:
                print(f"[PDF EXPORT] Error creating PDF for board {board.id}: {e}")
                return False
        
        # Recursive function to process folders and create PDFs
        def process_folder(folder, parent_path):
            """Recursively process folder and create PDFs for all content"""
            # Create folder directory
            folder_name = sanitize_filename(folder.name)
            folder_path = os.path.join(parent_path, folder_name)
            os.makedirs(folder_path, exist_ok=True)
            
            # Process all notes in this folder
            notes = Note.query.filter_by(folder_id=folder.id, user_id=user_id).all()
            for note in notes:
                create_note_pdf(note, folder_path)
            
            # Process all boards in this folder
            boards = Board.query.filter_by(folder_id=folder.id, user_id=user_id).all()
            for board in boards:
                create_board_pdf(board, folder_path)
            
            # Process subfolders recursively
            subfolders = Folder.query.filter_by(parent_id=folder.id, user_id=user_id).all()
            for subfolder in subfolders:
                process_folder(subfolder, folder_path)
        
        # Start processing from the root folder
        root_path = os.path.join(temp_dir, sanitize_filename(start_folder.name))
        os.makedirs(root_path, exist_ok=True)
        process_folder(start_folder, temp_dir)
        
        # Create ZIP file
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # Walk through the temp directory and add all files
            for root, dirs, files in os.walk(temp_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    # Calculate the archive name (relative path)
                    arcname = os.path.relpath(file_path, temp_dir)
                    zip_file.write(file_path, arcname)
        
        zip_buffer.seek(0)
        
        # Clean up temp directory
        shutil.rmtree(temp_dir)
        
        # Generate filename
        zip_filename = f"{username}_{start_folder.name}_PDFs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        
        flash(f"PDF export complete! Downloaded as ZIP with folder structure maintained.", "success")
        return send_file(
            zip_buffer,
            mimetype="application/zip",
            as_attachment=True,
            download_name=zip_filename
        )
    
    except Exception as e:
        print(f"[PDF EXPORT] Error: {e}")
        import traceback
        traceback.print_exc()
        
        # Clean up temp directory in case of error
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        
        flash(f"Error creating PDF export: {str(e)}", "danger")
        return redirect(url_for("folders.view_folder", folder_id=current_folder_id))

